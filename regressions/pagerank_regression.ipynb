{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('refpages', 'backlinks'), ('valid_pages', 'pages'), ('text', 'backlinks'), ('text', 'refpages'), ('image', 'backlinks'), ('image', 'refpages'), ('image', 'text'), ('nofollow', 'backlinks'), ('nofollow', 'refpages'), ('nofollow', 'text'), ('nofollow', 'image'), ('dofollow', 'backlinks'), ('dofollow', 'refpages'), ('dofollow', 'text'), ('dofollow', 'image'), ('dofollow', 'nofollow'), ('gov', 'backlinks'), ('gov', 'refpages'), ('gov', 'text'), ('gov', 'image'), ('gov', 'nofollow'), ('gov', 'dofollow'), ('edu', 'backlinks'), ('edu', 'refpages'), ('edu', 'text'), ('edu', 'image'), ('edu', 'nofollow'), ('edu', 'dofollow'), ('edu', 'gov'), ('html_pages', 'pages'), ('html_pages', 'valid_pages'), ('refclass_c', 'refdomains'), ('refips', 'refdomains'), ('refips', 'refclass_c')]\n",
      "['valid_pages', 'refclass_c', 'refdomains', 'image', 'nofollow', 'dofollow', 'text', 'pages', 'gov', 'refpages']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from functools import reduce\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# no true true\n",
    "bias_transformed = False\n",
    "bias_untransformed = False\n",
    "\n",
    "output_folder = '../results/'\n",
    "bias_output_folder = '../results/transformed/'\n",
    "log = True\n",
    "traffic_df = pd.read_csv ('../data/traffic.csv')\n",
    "rank_df = traffic_df.copy()\n",
    "bias_attribute_path = '../results/transformed_features.csv'\n",
    "attribute_path = '../data/filtered_attrs.csv'\n",
    "attribute_df = pd.read_csv (attribute_path)\n",
    "attribute_df = attribute_df[attribute_df['source'] == 'MBFC']\n",
    "reg_var = 'traffic'\n",
    "\n",
    "if bias_transformed:\n",
    "    attribute_df = pd.read_csv (bias_attribute_path)\n",
    "    # filter and reorder traffic_dc according to attribute_df['url']\n",
    "    traffic_mod = pd.merge(traffic_df[['url', reg_var, 'rank']], attribute_df, on='url', how='inner')\n",
    "    traffic_df = traffic_mod[['url', reg_var]]\n",
    "    rank_df = traffic_mod[['url', 'rank']]\n",
    "    attribute_df = traffic_mod.drop(columns=[reg_var, 'rank', 'bias'])\n",
    "    output_folder = bias_output_folder\n",
    "elif bias_untransformed:\n",
    "    bias_attribute_path = '../results/transformed_features.csv'\n",
    "    bias_attribute_df = pd.read_csv (bias_attribute_path)\n",
    "    attribute_df = pd.merge(attribute_df, bias_attribute_df['url'], on='url', how='inner')\n",
    "    traffic_mod = pd.merge(traffic_df[['url', reg_var, 'rank']], attribute_df, on='url', how='inner')\n",
    "    traffic_df = traffic_mod[['url', reg_var]]\n",
    "    rank_df = traffic_mod[['url', 'rank']]\n",
    "    output_folder = bias_output_folder + 'orig_'\n",
    "    # drop \n",
    "urls_to_remove = ['youtube.com', 'facebook.com']\n",
    "for url in urls_to_remove:\n",
    "    traffic_df = traffic_df[~traffic_df['url'].str.contains(url)]\n",
    "    attribute_df = attribute_df[~attribute_df['url'].str.contains(url)]\n",
    "\n",
    "prdf = pd.read_csv('../data/cc_link_scheme_removal_results.csv').dropna()\n",
    "prdf = prdf[prdf.url.isin(attribute_df.url.tolist())]\n",
    "attribute_df = attribute_df[attribute_df.url.isin(prdf.url.tolist())]\n",
    "prdf = prdf.sort_values('url')\n",
    "attribute_df = attribute_df.sort_values('url')\n",
    "np.array_equal(prdf.url.values, attribute_df.url.values)\n",
    "\n",
    "# merge traffic data with backlinks data\n",
    "url_df = attribute_df.copy() #pd.merge(traffic_df, attribute_df, on='url', how='inner')\n",
    "url_df.dropna(inplace=True)\n",
    "\n",
    "features_to_keep = ['backlinks']#, 'ref_pages''edu', 'gov', 'ugc']\n",
    "drop_vars = ['source', 'url', 'linked_root_domains']\n",
    "for var in drop_vars:\n",
    "    if var in url_df.columns:\n",
    "        url_df.drop(columns=var, inplace=True)\n",
    "\n",
    "# remove correlated features\n",
    "correlation_matrix = url_df.corr()\n",
    "correlated_features = set()\n",
    "correlated_pairs = []\n",
    "for i in range(len(correlation_matrix .columns)):\n",
    "    for j in range(i):\n",
    "        if abs(correlation_matrix.iloc[i, j]) > 0.9:\n",
    "            colname = correlation_matrix.columns[j]\n",
    "            correlated_features.add(colname)\n",
    "            correlated_pairs.append((correlation_matrix.columns[i], colname))\n",
    "print(correlated_pairs)\n",
    "\n",
    "correlated_features = [x for x in correlated_features if not x in features_to_keep]\n",
    "print(correlated_features)\n",
    "uncorrelated_df = url_df.drop(columns=list(correlated_features))\n",
    "\n",
    "# log of features\n",
    "uncorrelated_log_df = uncorrelated_df.clip(lower=0)\n",
    "\n",
    "if log:\n",
    "    for col in (uncorrelated_log_df.columns):\n",
    "        if col == 'label':\n",
    "            continue\n",
    "        uncorrelated_log_df[col] = np.log(1+uncorrelated_log_df[col])\n",
    "\n",
    "\n",
    "traffic_df = traffic_df[traffic_df.url.isin(attribute_df.url.tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                      y   R-squared (uncentered):                   0.976\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.976\n",
      "Method:                 Least Squares   F-statistic:                          1.243e+04\n",
      "Date:                Tue, 13 Feb 2024   Prob (F-statistic):                        0.00\n",
      "Time:                        14:23:00   Log-Likelihood:                         -6024.3\n",
      "No. Observations:                2728   AIC:                                  1.207e+04\n",
      "Df Residuals:                    2719   BIC:                                  1.212e+04\n",
      "Df Model:                           9                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1            -1.7390      0.024    -72.189      0.000      -1.786      -1.692\n",
      "x2             0.4840      0.039     12.470      0.000       0.408       0.560\n",
      "x3             0.4543      0.032     14.258      0.000       0.392       0.517\n",
      "x4             0.0949      0.015      6.495      0.000       0.066       0.124\n",
      "x5             0.6203      0.024     25.710      0.000       0.573       0.668\n",
      "x6             0.2835      0.020     14.108      0.000       0.244       0.323\n",
      "x7             0.4417      0.047      9.325      0.000       0.349       0.535\n",
      "x8            -0.4420      0.043    -10.339      0.000      -0.526      -0.358\n",
      "x9            -0.0743      0.040     -1.837      0.066      -0.154       0.005\n",
      "==============================================================================\n",
      "Omnibus:                       51.491   Durbin-Watson:                   1.852\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               88.248\n",
      "Skew:                           0.146   Prob(JB):                     6.87e-20\n",
      "Kurtosis:                       3.832   Cond. No.                         41.1\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] RÂ² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "insignificant_features = { \n",
    "    'label': [],#'pages', 'backlinks', 'valid_pages', 'canonical', 'gov','edu', 'rss', 'alternate', 'html_pages', 'links_internal', 'links_external'],\n",
    "    'rank': ['rss','sponsored','alternate'],#'canonical', 'rss', 'alternate', 'html_pages', 'links_external', 'linked_root_domains'],\n",
    "    'traffic': ['rss','sponsored'],#['rss', 'sponsored', 'redirect', 'ugc','canonical','edu','alternate', 'label', 'refips', 'links_internal'],#'linked_root_domains', 'links_internal', 'refpages'],\n",
    "    'traffic_top3': ['rss', 'linked_root_domains', 'links_internal', 'html_pages'],\n",
    "    'traffic_top10': [],\n",
    "    'cost':[],\n",
    "    'positions':[],\n",
    "}\n",
    "\n",
    "# if transformed:\n",
    "#     insignificant_features['traffic'] = ['links_external', 'gov', 'edu', 'redirect', 'dofollow', 'valid_pages','backlinks', 'html_pages', 'image']\n",
    "\n",
    "# train, test, labels, y_test = train_test_split(uncorrelated_log_df, traffic_df, test_size=0.1, random_state=63)\n",
    "train = uncorrelated_log_df.copy()\n",
    "test = uncorrelated_log_df.copy()\n",
    "labels = prdf.copy()\n",
    "y_test = prdf.copy()\n",
    "y_train = np.log(prdf['cc-orig-pr'])\n",
    "\n",
    "X_train = train.drop(columns=insignificant_features[reg_var]) \n",
    "\n",
    "features = X_train.columns.to_list()\n",
    "\n",
    "# regressor = LinearRegression()  \n",
    "# model = regressor.fit(X_train, y_train)\n",
    "# print(\"Coef:\", model.coef_)\n",
    "# print(\"Constant:\", model.intercept_)\n",
    "# print(\"R2:\", model.score(X_train, y_train))\n",
    "model = sm.OLS\n",
    "est = sm.OLS(y_train.values, X_train.drop(columns=['label','refips']).values)\n",
    "est2 = est.fit()\n",
    "\n",
    "print(est2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.8489665202995305"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check MSE\n",
    "ypred = est2.predict(X_train.drop(columns=['label','refips']).values)\n",
    "np.mean((ypred - y_train)**2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
